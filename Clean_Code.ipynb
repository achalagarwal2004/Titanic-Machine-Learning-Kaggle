{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Titanic Survival Prediction - Kaggle Competition\n",
    "=================================================\n",
    "This notebook builds a machine learning model to predict passenger survival \n",
    "on the Titanic using Random Forest and other classification algorithms.\n",
    "\n",
    "Dataset: Kaggle Titanic Competition\n",
    "Author: Achal Agarwal\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Set path to data directory\n",
    "path = 'C:/Users/Achal Agarwal/OneDrive/Kaggle/Titanic/'\n",
    "\n",
    "# Load training data, test data, and sample submission\n",
    "train_data = pd.read_csv(path + 'data/train.csv')\n",
    "test_data = pd.read_csv(path + 'data/test.csv')\n",
    "gender_submission = pd.read_csv(path + 'data/gender_submission.csv')\n",
    "\n",
    "# Display first 50 rows to understand data structure\n",
    "train_data.head(50)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate survival rate for women\n",
    "women = train_data[train_data['Sex'] == 'female']['Survived']\n",
    "rate_women = sum(women) / len(women) * 100\n",
    "print(f\"Women survival rate: {rate_women:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DATA CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(train_data[[\"Age\", \"Fare\", \"Embarked\"]].isnull().sum())\n",
    "\n",
    "# Fill missing Age values with median (more robust to outliers than mean)\n",
    "train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing Fare values with median\n",
    "train_data['Fare'].fillna(train_data['Fare'].median(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].median(), inplace=True)\n",
    "\n",
    "# Fill missing Embarked values with mode (most common port)\n",
    "train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)\n",
    "test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(train_data[[\"Age\", \"Fare\", \"Embarked\"]].isnull().sum())\n",
    "\n",
    "# ============================================================================\n",
    "# 5. FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "# Create FamilySize feature (total family members aboard)\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "# Create IsAlone feature (1 if traveling alone, 0 otherwise)\n",
    "train_data['IsAlone'] = (train_data['FamilySize'] == 1).astype(int)\n",
    "test_data['IsAlone'] = (test_data['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Extract Title from passenger names (Mr, Mrs, Miss, Master, etc.)\n",
    "train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Group rare titles into 'Rare' category\n",
    "rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', \n",
    "               'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "train_data['Title'] = train_data['Title'].replace(rare_titles, 'Rare')\n",
    "test_data['Title'] = test_data['Title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "# Standardize similar titles\n",
    "train_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\n",
    "train_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\n",
    "train_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "test_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\n",
    "test_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\n",
    "test_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Define feature list for model training\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \n",
    "            \"Embarked\", \"FamilySize\", \"IsAlone\", \"Title\"]\n",
    "\n",
    "# ============================================================================\n",
    "# 6. PREPARE DATA FOR MODELING\n",
    "# ============================================================================\n",
    "\n",
    "# Separate target variable (Survived)\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "# Apply one-hot encoding to categorical features\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "# Ensure test data has same columns as training data\n",
    "# Missing columns are filled with 0, extra columns are dropped\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# ============================================================================\n",
    "# 7. MODEL TRAINING - RANDOM FOREST\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize Random Forest with tuned hyperparameters\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,       # Number of trees in the forest\n",
    "    max_depth=7,            # Maximum depth of each tree\n",
    "    min_samples_split=4,    # Minimum samples required to split a node\n",
    "    random_state=1          # For reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "output = pd.DataFrame({\n",
    "    'PassengerId': test_data.PassengerId, \n",
    "    'Survived': predictions\n",
    "})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"âœ… Submission file created: my_submission.csv\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"All 5 fold scores: {scores}\")\n",
    "print(f\"Average accuracy: {scores.mean():.4f}\")\n",
    "print(f\"Standard deviation: {scores.std():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. COMPARE MULTIPLE MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n=== Comparing Different Models ===\")\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, max_depth=7, random_state=1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=1),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=1)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. STRATIFIED K-FOLD VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "# Use stratified k-fold to maintain class distribution in each fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"\\n=== Stratified K-Fold Results ===\")\n",
    "print(f\"Mean accuracy: {scores.mean():.4f}\")\n",
    "print(f\"Standard deviation: {scores.std():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 11. HYPERPARAMETER TUNING (OPTIONAL)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n=== Hyperparameter Tuning ===\")\n",
    "\n",
    "# Define parameter distribution for random search\n",
    "param_dist = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [5, 7, 10, None],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['sqrt', 0.5, 1.0],\n",
    "}\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=1),\n",
    "    param_dist, \n",
    "    n_iter=20,              # Number of parameter combinations to try\n",
    "    cv=cv, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,              # Use all CPU cores\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "\n",
    "print(f\"Best cross-validation score: {search.best_score_:.4f}\")\n",
    "print(f\"Best parameters: {search.best_params_}\")\n",
    "\n",
    "# ============================================================================\n",
    "# END OF NOTEBOOK\n",
    "# ============================================================================"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
